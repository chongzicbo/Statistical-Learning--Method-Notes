# 4. 朴素贝叶斯法

&emsp;&emsp;朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法。利用特征条件独立学习输入输出的联合概率分布，然后对给定的输入$x$,利用贝叶斯定理求出后验概率最大的输出$y$。

## 4.1 朴素贝叶斯法的学习

&emsp;&emsp;输入为特征向量$x \in X \subseteq R^n$,输出为类标记$y \in Y=\{ c_1,c_2, \ldots, c_K\}$。$X,Y$分别为输入空间和输出空间。$P(X,Y)$为$X$和$Y$的联合概率分布。训练数据集
$$
T=\{(x_1,y_1),(x_2,y_2),\dots,(x_N,y_N)\}
$$
由$P(X,Y)$独立同分布产生。

&emsp;&emsp;朴素贝叶斯法首先学习先验概率分布
$$
P(Y=c_k),k=1,2,\dots,K
$$
和条件概率分布
$$
P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},\dots,X^{(n)}=x^{(n)}),k=1,2,\dots,K
$$
从而学习到联合概率分布$P(X,Y)$。
但是条件概率分布$P(X=x|Y=c_k)$有指数级数量的参数,其估计实际是不可行的.因此，贝叶斯法对条件概率分布作了条件独立性假设，即用于分类的特征在类确定的条件下都是条件独立的:
$$
P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},\dots,X^{(n)}=x^{(n)}|Y=c_k) \\
=\prod _{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k)
$$

朴素贝叶斯法属于生成模型，学习到生成数据的机制。

## 4.2 朴素贝叶斯法的分类

&emsp;&emsp;朴素贝叶斯法在分类时，对给定的输入$x$，通过学习到的模型计算后验概率分布$P(Y=c_k|X=x)$，将后验概率最大的类作为$x$的类输出。后验概率根据贝叶斯定理计算：
$$
P(Y=c_k|X=x)=\frac{P(X=x|Y=c_k)P(Y=c_k)}{\sum _{k}P(X=x|Y=c_k)P(Y=c_k)} \\
=\frac{P(Y=c_k) \prod _jP(X^{(j)}=x^{(j)}|Y=c_k)}{\sum _kP(Y=c_k) \prod _jP(X^{(j)}=x^{(j)}|Y=c_k)}
$$

于是，朴素贝叶斯分类器可表示为：
$$
y=f(x)=\argmax _{c_k}\frac{P(Y=c_k) \prod _jP(X^{(j)}=x^{(j)}|Y=c_k)}{\sum _kP(Y=c_k) \prod _jP(X^{(j)}=x^{(j)}|Y=c_k)}
$$

上式中分母对所有$c_k$都是相同的，所以：
$$
y=f(x)=\argmax _{c_k}P(Y=c_k) \prod _jP(X^{(j)}=x^{(j)}|Y=c_k)
$$

## 4.3 朴素贝叶斯法的参数估计

### 4.3.1 极大似然估计

输入：训练数据集$T=\{(x_1,y_1),(x_2,y_2),\dots,(x_N,y_N) \}$，其中$x_i=(x_i^{(1)},x_i^{(2)},\ldots,x_i^{(n)})^T$，$x_i^{(j)}$是第$i$个样本的第$j$个特征，$x_i^{(j)} \in \{ a_{j1},a_{j2},\ldots,a_{js_j}\}$，$a_{jl}$是第$j$个特征可能取的第$l$个值，$j=1,2,\dots,n,l=1,2,\dots,S_j$,$y_i \in\{c_1,c_2,\dots,c_K\}$

输出：实例$x$的分类

（1）计算先验概率及条件概率

$$
P(Y=c_k)=\frac{ \sum _{i=1}^N I(y_i=c_k)}{N},k=1,2,\dots,K
$$

$$
P(X^{(j)}=a_{jl}|Y=c_k)=\frac{ \sum _{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)}{\sum_{i=1}^NI(y_i=c_k)}
$$

(2)对于给定的实例$x=(x^{(1)},x^{(2)},\dots,x^{(n)})^T$，计算：
$$
P(Y=c_k)\prod _{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k)
$$

(3)确定实例$x$的类

$$
y=\argmax _{c_k}P(Y=c_k)\prod _{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k)
$$

### 4.3.2 贝叶斯估计

&emsp;&emsp;用极大似然估计可能会出现概率值为0的情况，会影响到后验概率的计算结果，使分类产生偏差，解决这一问题可以使用贝叶斯估计。条件概率的贝叶斯估计是：

$$
P_\lambda(X^{(j)}=a_{jl}|Y=c_k)=\frac{ \sum _{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)+\lambda}{\sum_{i=1}^NI(y_i=c_k)+S_j\lambda}
$$
其中,$\lambda \geqslant0$,当$\lambda=0$时就是极大似然估计,常取$\lambda=1$,称为拉普拉斯平滑。

先验概率的贝叶斯估计为：

$$
P(Y=c_k)=\frac{ \sum _{i=1}^N I(y_i=c_k)+\lambda}{N+K\lambda},k=1,2,\dots,K
$$

